{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# To display the all columns in pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the training data\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of rows/columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the data to see sample rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get some basic stats <- not much help here as there are 50+ columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check to see missing values. As seen below, Alley doesn't have much data. FireplaceQu has 50% missing. PoolQC, Fence and Misc are also rare.\n",
    "# Count doesn't include NaN values. If you want length, use len(df.index). Alsom df.dtypes gives object types\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the histogram to see the SalePrice. This shows that most of the houses are within 100k-250k range. (almost ~1100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.SalePrice.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features\n",
    "There are multiple ideas that can be explored next. Since there are 81 features, I think not all are important. We can bucket these features into categories and can find correlatiom in them. Two things to keep in mind - handle NaN values and convert object to int. \n",
    "\n",
    "#### Basement:\n",
    "BsmtQual         1423   \n",
    "BsmtCond         1423   \n",
    "BsmtExposure     1422   \n",
    "BsmtFinType1     1423   \n",
    "BsmtFinSF1       1460   \n",
    "BsmtFinType2     1422   \n",
    "BsmtFinSF2       1460   \n",
    "\n",
    "#### Garage:\n",
    "GarageType       1379   \n",
    "GarageYrBlt      1379   \n",
    "GarageFinish     1379   \n",
    "GarageCars       1460   \n",
    "GarageArea       1460   \n",
    "GarageQual       1379   \n",
    "GarageCond       1379   \n",
    "\n",
    "So from the above two types, I we can see that for Basement, NA\tNo Basement is just NaN. So we need to convert NaNs to NA. Same with garage - convert NaNs to NA No Garage. The ints will still be 0. \n",
    "   \n",
    "Also do the same for Fence (NaN -> NA), Pool (NaN -> NA), Misc (NaN->NA)\n",
    "\n",
    "For  LotFrontage -> NaN should be converted to 0 as it is an int type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filling missing values\n",
    "df['BsmtQual'] = df['BsmtQual'].fillna(\"NA\")\n",
    "df['BsmtCond'] = df['BsmtCond'].fillna(\"NA\")\n",
    "df['BsmtExposure'] = df['BsmtExposure'].fillna(\"NA\")\n",
    "df['BsmtFinType1'] = df['BsmtFinType1'].fillna(\"NA\")\n",
    "df['BsmtFinType2'] = df['BsmtFinType2'].fillna(\"NA\")\n",
    "\n",
    "df['GarageType'] = df['GarageType'].fillna(\"NA\")\n",
    "df['GarageYrBlt'] = df['GarageYrBlt'].fillna(0.0)\n",
    "df['GarageFinish'] = df['GarageFinish'].fillna(\"NA\")\n",
    "df['GarageQual'] = df['GarageQual'].fillna(\"NA\")\n",
    "df['GarageCond'] = df['GarageCond'].fillna(\"NA\")\n",
    "\n",
    "df['FireplaceQu'] = df['FireplaceQu'].fillna(\"NA\")\n",
    "\n",
    "df['LotFrontage'] = df['LotFrontage'].fillna(0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Starting feature engineering. Taking each column and doing some analysis to figure out if we will keep the column or drop the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.crosstab(df['SalePrice'], df['MSSubClass'])\n",
    "df1.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.hist(column=\"SalePrice\",by=\"MSSubClass\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# comparing the value counts with histogram, we can see that the top three entries have similar shape but since \n",
    "# data is sparse, we can keep this. We will keep MSSubClass\n",
    "df.MSSubClass.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.crosstab(df['SalePrice'], df['MSZoning'])\n",
    "df1.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RL and RM looks like same plots. The rest three add up to 91. We will drop MSZoning.\n",
    "print df.MSZoning.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"MSZoning\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Determine pivot table. We can see that higher the LotArea, more the price. We will keep LotArea\n",
    "impute_grps = df.pivot_table(values=[\"SalePrice\"], index=[\"LotArea\"], aggfunc=np.mean).plot()\n",
    "print impute_grps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reg and IR1 has the same shape. So not much info here. We will drop LotShape\n",
    "print df.LotShape.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"LotShape\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Street is not a good signal. We will drop Street\n",
    "print df.Street.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"Street\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Land contour doesn't have a lot of variation. We will drop LandContour\n",
    "print df.LandContour.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"LandContour\",bins=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Utilities is not a good column as there is no variation. We will drop Utilities\n",
    "df['Utilities'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On the edge for this. We can keep LotConfig\n",
    "print df.LotConfig.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"LotConfig\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# More than 90% of the data is from a single value. We will drop LandSlope\n",
    "print df.LandSlope.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"LandSlope\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can keep this for now as there is some value here. We will keep Neighborhood\n",
    "print df.Neighborhood.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"Neighborhood\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Not sure of this signal. We can revisit it later. We will keep Condition1\n",
    "print df.Condition1.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"Condition1\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Most of condition 2 is normal. We will drop Condition2\n",
    "print df.Condition2.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"Condition2\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On the edge. We will revisit it. We will keep BldgType\n",
    "print df.BldgType.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"BldgType\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Is there a way to combine HouseStyle and BldgType? We can find some correlation? We will keep HouseStyle\n",
    "print df.HouseStyle.value_counts() \n",
    "df.hist(column=\"SalePrice\",by=\"HouseStyle\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Not sure how to find correlation as both the values are objects.\n",
    "df.filter(items=[\"BldgType\", \"HouseStyle\"]).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will keep OverallQual\n",
    "print df.OverallQual.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"OverallQual\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Is there a correlation with OverallQual? We will keep OverallCond\n",
    "print df.OverallCond.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"OverallCond\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for correlation\n",
    "df.filter(items=[\"OverallQual\", \"OverallCond\"]).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# YearBuilt is a good signal as the price increases as teh year increases. We will keep YearBuilt\n",
    "df.pivot_table(values=[\"SalePrice\"], index=[\"YearBuilt\"], aggfunc=np.mean).plot()\n",
    "#print df.YearBuilt.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# looks like a good signal. We need to find correlation with year built.\n",
    "#print df.YearRemodAdd.value_counts()\n",
    "df.pivot_table(values=[\"SalePrice\"], index=[\"YearRemodAdd\"], aggfunc=np.mean).plot()\n",
    "\n",
    "# It has around 0.6 correlation. We will drop YearRemodAdd\n",
    "df.filter(items=[\"YearBuilt\", \"YearRemodAdd\"]).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gable and Hip has similar histograms. This signal is not adding value. We will drop RoofStyle\n",
    "print df.RoofStyle.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"RoofStyle\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will drop RoofMatl\n",
    "print df.RoofMatl.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"RoofMatl\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Clean up the values\n",
    "df['Exterior2nd'] = df['Exterior2nd'].str.replace(\"CmentBd\",\"CemntBd\")\n",
    "df['Exterior2nd'] = df['Exterior2nd'].str.replace(\"Wd Shng\",\"WdShing\")\n",
    "\n",
    "# only 139 values are different. Hence both of them are highly correlated. Hence just need once. We will keep Exterior1st\n",
    "# We will drop Exterior2nd\n",
    "df[df.Exterior1st != df.Exterior2nd].filter(items=[\"Exterior1st\", \"Exterior2nd\", \"SalePrice\"]).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Not sure about this as 50% of values are None (which is a valid type). We will keep MasVnrType\n",
    "print df.MasVnrType.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"MasVnrType\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MasVnrArea is a good signal to keep. We will keep MasVnrArea\n",
    "#print df.MasVnrArea.value_counts()\n",
    "df.pivot_table(values=[\"SalePrice\"], index=[\"MasVnrArea\"], aggfunc=np.mean).plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# It can be a okay signal. We will keep ExterQual\n",
    "print df.ExterQual.value_counts()\n",
    "print df.filter(items=['ExterQual', 'ExterCond']).apply(pd.Series.value_counts)\n",
    "\n",
    "df.hist(column=\"SalePrice\",by=\"ExterQual\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Doesn't look like a good signal as TA+Gd covers most data. We will drop ExterCond\n",
    "print df.ExterCond.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"ExterCond\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Need to revisit. We will keep Foundation\n",
    "print df.Foundation.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"Foundation\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Basement analysis\n",
    "# BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinSF1, BsmtFinType2, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF\n",
    "\n",
    "# BsmtQual is a good signal as seen in the histograms. We will keep BsmtQual\n",
    "print df.BsmtQual.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"BsmtQual\",bins=10)\n",
    "\n",
    "# Gd and TA are almost same. Fa + Po is just 47/1460. We will drop BsmtCond\n",
    "print df.BsmtCond.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"BsmtCond\",bins=10)\n",
    "\n",
    "# The histograms for top values look the same. Revisit this later. We will drop BsmtExposure\n",
    "print df.BsmtExposure.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"BsmtExposure\",bins=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# As seen below: TotalBsmtSF = BsmtFinSF1 + BsmtFinSF2 + BsmtUnfSF\n",
    "df.filter(items=[\"BsmtFinType1\", \"BsmtFinSF1\", \"BsmtFinType2\", \"BsmtFinSF2\", \"BsmtUnfSF\", \"TotalBsmtSF\", \"SalePrice\"]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Based on histograms and above table, this can be an useful signal. We will keep BsmtFinType1\n",
    "print df.BsmtFinType1.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"BsmtFinType1\",bins=10)\n",
    "\n",
    "# 1256/1460 is Unf. Not a lot of variation in other items. We will drop BsmtFinType2\n",
    "print df.BsmtFinType2.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"BsmtFinType2\",bins=10)\n",
    "\n",
    "# Based on above table, this can be an useful signal. We will keep BsmtFinSF1\n",
    "df.pivot_table(values=[\"SalePrice\"], index=[\"BsmtFinSF1\"], aggfunc=np.mean).plot()\n",
    "\n",
    "# BsmtFinSF2 will be mostly 0 as there is a different column for Unf. We will drop BsmtFinSF2\n",
    "df.pivot_table(values=[\"SalePrice\"], index=[\"BsmtFinSF2\"], aggfunc=np.mean).plot()\n",
    "\n",
    "# BsmtUnfSF will be populated whenever there is unf in basement. Hence we can keep this over TotalBsmtSF \n",
    "# We will keep BsmtUnfSF\n",
    "df.pivot_table(values=[\"SalePrice\"], index=[\"BsmtUnfSF\"], aggfunc=np.mean).plot()\n",
    "\n",
    "# TotalBsmtSF = BsmtFinSF1 + BsmtFinSF2 + BsmtUnfSF. Since BsmtFinSF2 will be zero for 91.4% of times, BsmtFinSF1 + BsmtUnfSF \n",
    "# will a good indication for TotalBsmtSF. We will drop TotalBsmtSF\n",
    "df.pivot_table(values=[\"SalePrice\"], index=[\"TotalBsmtSF\"], aggfunc=np.mean).plot()\n",
    "\n",
    "# The graphs for BsmtFinSF1 and TotalBsmtSF are similar. The correlation is 0.52 and hence we can drop TotalBsmtSF\n",
    "print df.filter(items=[\"BsmtFinSF1\", \"TotalBsmtSF\"]).corr()\n",
    "\n",
    "# There is a -0.49 correlation but I still feel that we can keep both. We can revisit it later to change it\n",
    "print df.filter(items=[\"BsmtFinSF1\", \"BsmtUnfSF\"]).corr()\n",
    "\n",
    "### Note: One thing I need to understand is how can we tell about these dependent cols to the ML algo. E.g. BsmtFinType1 \n",
    "### and BsmtFinSF1 are related but ML algo will think about them as independent cols. We lose informtion here. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Grav + Wall = 11/1460. For these two, the Saleprice is < 120k. But the amount is less to make any impact. \n",
    "# We will drop Heating\n",
    "print df.Heating.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"Heating\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This can be a good signal as most house prices are < 200k for TA + Gd but there are around 200 houses whose saleprice\n",
    "# is >200k as it is Ex. We will keep HeatingQC\n",
    "print df.HeatingQC.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"HeatingQC\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Need to revisit it. If the value is N, then we can see that the house price will be less than 250k. \n",
    "# We will keep CentralAir \n",
    "print df.CentralAir.value_counts()\n",
    "print df[df.SalePrice < 70000].CentralAir.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"CentralAir\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Need to revisit it.Not enough data. We will drop Electrical\n",
    "print df.Electrical.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"Electrical\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Bedroom/Bathroom sizes\n",
    "# 1stFlrSF, 2ndFlrSF, LowQualFinSF, GrLivArea, BsmtFullBath, BsmtHalfBath, FullBath, HalfBath, BedroomAbvGr, TotRmsAbvGrd\n",
    "\n",
    "df1 = df.filter(items=[\"1stFlrSF\", \"2ndFlrSF\", \"LowQualFinSF\", \"GrLivArea\", \"BsmtFullBath\", \"BsmtHalfBath\", \"FullBath\", \"HalfBath\", \"BedroomAbvGr\", \"TotRmsAbvGrd\", \"SalePrice\"])\n",
    "\n",
    "# Just 26 values for LowQualFinSF. We will drop LowQualFinSF\n",
    "print df1[df1.LowQualFinSF != 0].LowQualFinSF.count()\n",
    "\n",
    "# GrLivArea = 1stFlrSF + 2ndFlrSF. We will drop 1stFlrSF and 2ndFlrSF. We will keep GrLivArea\n",
    "\n",
    "# Need to revisit if we want BedroomAbvGr/TotRmsAbvGrd as it directly correlates to GrLivArea. It is 0.82. \n",
    "# We will drop TotRmsAbvGrd and BedroomAbvGr\n",
    "print df.BedroomAbvGr.value_counts()\n",
    "print df.TotRmsAbvGrd.value_counts()\n",
    "df.pivot_table(values=[\"SalePrice\"], index=[\"BedroomAbvGr\"], aggfunc=np.mean).plot()\n",
    "df.pivot_table(values=[\"SalePrice\"], index=[\"TotRmsAbvGrd\"], aggfunc=np.mean).plot()\n",
    "df.pivot_table(values=[\"SalePrice\"], index=[\"GrLivArea\"], aggfunc=np.mean).plot()\n",
    "df.filter(items=[\"BedroomAbvGr\", \"TotRmsAbvGrd\", \"GrLivArea\" ]).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will drop BsmtFullBath, BsmtHalfBath, FullBath, HalfBath. We will keep df1['BsmtBath'] = df1['BsmtFullBath'] + df1['BsmtHalfBath']\n",
    "# and df1['Bath'] = df1['FullBath'] + df1['HalfBath']\n",
    "df1 = df.filter(items=[\"BsmtFullBath\", \"BsmtHalfBath\", \"FullBath\", \"HalfBath\", \"SalePrice\"])\n",
    "df1['BsmtBath'] = df1['BsmtFullBath'] + df1['BsmtHalfBath']\n",
    "df1['Bath'] = df1['FullBath'] + df1['HalfBath']\n",
    "\n",
    "print df1.head(10)\n",
    "#print df.BsmtFullBath.value_counts()\n",
    "#print df.BsmtHalfBath.value_counts()\n",
    "#print df.FullBath.value_counts()\n",
    "#print df.HalfBath.value_counts()\n",
    "\n",
    "df1.hist(column=\"SalePrice\",by=\"BsmtBath\",bins=10)\n",
    "df1.hist(column=\"SalePrice\",by=\"Bath\",bins=10)\n",
    "#df.hist(column=\"SalePrice\",by=\"FullBath\",bins=10)\n",
    "#df.hist(column=\"SalePrice\",by=\"HalfBath\",bins=10)\n",
    "\n",
    "# No strong correlation\n",
    "df1.filter(items=[\"BsmtBath\", \"Bath\"]).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Doesn't look like a good signal as have 1 or 2 kitchen don't change much. We will drop KitchenAbvGr\n",
    "print df.KitchenAbvGr.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"KitchenAbvGr\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Based on histograms, this looks like a good signal. We will keep KitchenQual\n",
    "print df.KitchenQual.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"KitchenQual\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Need to revisit it. I think we can club them together to make a binary - Typ / No Typ. \n",
    "# Less than 7% of the houses have any deductions. We will drop Functional\n",
    "print df.Functional.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"Functional\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fireplaces is a good signal as having a fireplace incresaes the SalePrice. We will keep Fireplaces\n",
    "print df.Fireplaces.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"Fireplaces\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FireplaceQu depends on number of Fireplaces. There are almost 50% houses without fireplaces. \n",
    "# Need to find a way to combine this with Fireplaces. I can see this as a useful signal as \n",
    "# Salesprice(Gd) > Salesprice(TA) > Salesprice(Fa). So need to revisit it. We will drop FireplaceQu\n",
    "print df.FireplaceQu.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"FireplaceQu\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Garage\n",
    "# GarageType, GarageYrBlt, GarageFinish, GarageCars, GarageArea, GarageQual, GarageCond\n",
    "df.filter(items=[\"GarageType\", \"GarageYrBlt\", \"GarageFinish\", \"GarageCars\", \"GarageArea\", \"GarageQual\", \"GarageCond\", \"SalePrice\"]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Removing the entries that doesn't have a garage, we can see 0.82 correlation between YearBuilt and GarageYrBlt. \n",
    "# We will drop GarageYrBlt\n",
    "df[df.GarageYrBlt != 0].filter(items=[\"YearBuilt\", \"YearRemodAdd\", \"GarageYrBlt\"]).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Most are TA + NA. Not much useful info. We will drop GarageQual\n",
    "print df.GarageQual.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"GarageQual\",bins=10)\n",
    "\n",
    "# Most are TA + NA. Not much useful info. We will drop GarageCond\n",
    "print df.GarageCond.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"GarageCond\",bins=10)\n",
    "\n",
    "# Looks like a good signal. We will keep GarageFinish\n",
    "print df.GarageFinish.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"GarageFinish\",bins=10)\n",
    "\n",
    "# We can keep this as the price for NA is less then Attach/Detach. We will keep GarageType\n",
    "print df.GarageType.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"GarageType\",bins=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "### Is there a correlation with GarageType and GarageFinish? Data shows that Attchd is mostly Rfn and Detchd is Unf.\n",
    "df1 = pd.crosstab(df['GarageFinish'], df['GarageType'])\n",
    "df1\n",
    "\n",
    "# Looking at the table, Unf is both for Attchd and Detchd. So we can keep this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GarageCars and GarageArea are related. We can revisit to see which one to keep\n",
    "# We will keep GarageCars. We will drop GarageArea\n",
    "print df.GarageCars.value_counts() \n",
    "df.pivot_table(values=[\"SalePrice\"], index=[\"GarageCars\"], aggfunc=np.mean).plot()\n",
    "\n",
    "df.pivot_table(values=[\"SalePrice\"], index=[\"GarageArea\"], aggfunc=np.mean).plot()\n",
    "\n",
    "# Having more cars means bigger GarageArea\n",
    "df.hist(column=\"GarageArea\",by=\"GarageCars\",bins=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# N/P has similar outlines. Data is sparse. We will drop PavedDrive\n",
    "print df.PavedDrive.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"PavedDrive\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Porch\n",
    "# Porch Analysis - Based on the graphs below, OpenPorchSF is a very ambigious value as it doesn't so any incresae or \n",
    "# decrease in SalePrice with increase in SF value. The rest three are good samples. Instead of three individual columns,\n",
    "# we can aggregate it into a single column. We will drop OpenPorchSF. We will keep df['AggPorch'] = df[\"ScreenPorch\"] + df[\"3SsnPorch\"] + df[\"EnclosedPorch\"]\n",
    "\n",
    "# Now lets see porch data\n",
    "df1 = df.filter(items=['ScreenPorch', '3SsnPorch', 'EnclosedPorch', 'OpenPorchSF', 'SalePrice'])\n",
    "df1['AggPorch'] = df1[\"ScreenPorch\"] + df1[\"3SsnPorch\"] + df1[\"EnclosedPorch\"] #+ df1[\"OpenPorchSF\"]\n",
    "print df1.head(10)\n",
    "print df1.describe()\n",
    "\n",
    "# Check price variation with porch\n",
    "df1.pivot_table(values=[\"SalePrice\"], index=[\"ScreenPorch\"], aggfunc=np.mean).plot()\n",
    "df1.pivot_table(values=[\"SalePrice\"], index=[\"3SsnPorch\"], aggfunc=np.mean).plot()\n",
    "df1.pivot_table(values=[\"SalePrice\"], index=[\"EnclosedPorch\"], aggfunc=np.mean).plot()\n",
    "df1.pivot_table(values=[\"SalePrice\"], index=[\"OpenPorchSF\"], aggfunc=np.mean).plot()\n",
    "df1.pivot_table(values=[\"SalePrice\"], index=[\"AggPorch\"], aggfunc=np.mean).plot()\n",
    "\n",
    "porchTot = []\n",
    "# only 116/1460 \n",
    "print \"ScreenPorch: \" + str(len(df[df['ScreenPorch'] != 0]))\n",
    "\n",
    "# only 24/1460\n",
    "print \"3SsnPorch: \" + str(len(df[df['3SsnPorch'] != 0]))\n",
    "\n",
    "# only 208/1460\n",
    "print \"EnclosedPorch: \" + str(len(df[df['EnclosedPorch'] != 0]))\n",
    "\n",
    "# only 804/1460\n",
    "print \"OpenPorchSF: \" + str(len(df[df['OpenPorchSF'] != 0]))\n",
    "\n",
    "# So 1152/1460 houses had a some kind of porch\n",
    "sumPorch = len(df[df['ScreenPorch'] != 0]) + len(df[df['3SsnPorch'] != 0]) + len(df[df['EnclosedPorch'] != 0]) + len(df[df['OpenPorchSF'] != 0])\n",
    "print \"sumPorch: \" + str(sumPorch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Only less than 50% of the houses has WoodDeckSF. Even those house that has WoodDeckSF, we can't see a clear trend.\n",
    "# We will drop WoodDeckSF\n",
    "print df[df.WoodDeckSF > 0].WoodDeckSF.count()\n",
    "\n",
    "df[df.WoodDeckSF > 0].pivot_table(values=[\"SalePrice\"], index=[\"WoodDeckSF\"], aggfunc=np.mean).plot()\n",
    "\n",
    "df[df.WoodDeckSF == 0].hist(column=\"SalePrice\",by=\"WoodDeckSF\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Only seven rows i.e. houses had a pool. We will drop PoolArea and PoolQC. \n",
    "print len(df[df.PoolArea != 0])\n",
    "df[df.PoolArea > 0].filter(items=['PoolArea', 'SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only 54 misc features are in the dataset. So 54/1460  = ~3.7%. Also, the shed is 49/54 misc vals and it\n",
    "# doesn't provide any info. We will drop MiscVal and MiscFeature\n",
    "print df.MiscFeature.count()\n",
    "print df.MiscFeature.value_counts()\n",
    "print df[df.MiscVal > 0].filter(items=['MiscFeature', 'SalePrice']).head(5)\n",
    "\n",
    "df[df.MiscFeature.notnull()].hist(column=\"SalePrice\",by=\"MiscFeature\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# More houses are sold in summer months. Houses in June are bit costlier. We can revisit this later to do another analysis\n",
    "# We will drop MoSold\n",
    "print df.MoSold.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"MoSold\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The mean prices of houses sold in 2008 fell by 10k from 2007 (financial crisis). People didn't buy anything costlier \n",
    "# than 450k in 2008. Other 4 years, there was atleast one house ~600k. Nothing glaring come out of this. \n",
    "# We can keep YrSold\n",
    "print df.YrSold.value_counts()\n",
    "df.pivot_table(values=[\"SalePrice\"], index=[\"YrSold\"], aggfunc=np.mean).plot()\n",
    "df.hist(column=\"SalePrice\",by=\"YrSold\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The min price of New type was 113k and the mean price is 10k higher than WD type. Other types are sparse\n",
    "# We can revisit it later. We will keep SaleType\n",
    "print df.SaleType.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"SaleType\",bins=10)\n",
    "print df[df.SaleType==\"New\"].SalePrice.describe()\n",
    "print df[df.SaleType==\"WD\"].SalePrice.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normal, partial and Abnorml kind of look the same. We will drop SaleCondition\n",
    "print df.SaleCondition.value_counts()\n",
    "df.hist(column=\"SalePrice\",by=\"SaleCondition\",bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Features To keep (Total: 32 columns):\n",
    "MSSubClass   \n",
    "LotArea   \n",
    "LotConfig   \n",
    "Neighborhood   \n",
    "Condition1   \n",
    "BldgType   \n",
    "HouseStyle   \n",
    "OverallQual   \n",
    "OverallCond   \n",
    "YearBuilt   \n",
    "Exterior1st   \n",
    "MasVnrType   \n",
    "MasVnrArea   \n",
    "ExterQual   \n",
    "Foundation   \n",
    "BsmtQual   \n",
    "BsmtFinType1   \n",
    "BsmtFinSF1   \n",
    "BsmtUnfSF   \n",
    "HeatingQC   \n",
    "CentralAir   \n",
    "GrLivArea   \n",
    "df1['BsmtBath'] = df1['BsmtFullBath'] + df1['BsmtHalfBath']   \n",
    "df1['Bath'] = df1['FullBath'] + df1['HalfBath']   \n",
    "KitchenQual   \n",
    "Fireplaces   \n",
    "GarageFinish   \n",
    "GarageType   \n",
    "GarageCars   \n",
    "df1['AggPorch'] = df1[\"ScreenPorch\"] + df1[\"3SsnPorch\"] + df1[\"EnclosedPorch”]   \n",
    "YrSold   \n",
    "SaleType   \n",
    "\n",
    "\n",
    "##### Features To drop (57 columns):\n",
    "MSZoning   \n",
    "LotShape   \n",
    "Street   \n",
    "LandContour   \n",
    "Utilities   \n",
    "LandSlope   \n",
    "Condition2   \n",
    "YearRemodAdd   \n",
    "RoofStyle   \n",
    "RoofMatl   \n",
    "Exterior2nd   \n",
    "ExterCond   \n",
    "BsmtCond   \n",
    "BsmtExposure   \n",
    "BsmtFinType2   \n",
    "BsmtFinSF2   \n",
    "TotalBsmtSF   \n",
    "Heating   \n",
    "Electrical   \n",
    "LowQualFinSF   \n",
    "1stFlrSF   \n",
    "2ndFlrSF   \n",
    "TotRmsAbvGrd   \n",
    "BedroomAbvGr   \n",
    "BsmtFullBath   \n",
    "BsmtHalfBath   \n",
    "FullBath   \n",
    "HalfBath   \n",
    "KitchenAbvGr   \n",
    "Functional   \n",
    "FireplaceQu   \n",
    "GarageYrBlt   \n",
    "GarageQual   \n",
    "GarageCond   \n",
    "GarageArea   \n",
    "PavedDrive   \n",
    "OpenPorchSF   \n",
    "ScreenPorch   \n",
    "3SsnPorch   \n",
    "EnclosedPorch   \n",
    "WoodDeckSF   \n",
    "PoolArea   \n",
    "PoolQC   \n",
    "MiscVal   \n",
    "MiscFeature   \n",
    "MoSold   \n",
    "SaleCondition   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a final df based on the cols we need. Also, add the new three cols\n",
    "finaldf = df.filter[items=[\"\", \"\"]]\n",
    "\n",
    "# check the dtypes of the df and convert objects into int by mapping them\n",
    "finaldf.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
